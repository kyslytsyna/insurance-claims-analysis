# ğŸ§  Insurance Claims Analysis (PySpark Project)

This project explores and models an **insurance claims dataset** using **PySpark** for distributed data processing and analysis.  
The goal is to understand key patterns in vehicle insurance data and build a foundation for claim prediction.

---

## ğŸ“‚ Project Structure

insurance-claims-analysis/
â”œâ”€â”€ main.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ preprocessed/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_EDA.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ model_training.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


---

## ğŸ” Current Progress

### Step 1: Environment Setup
- Created virtual environment (`venv`)
- Installed dependencies (PySpark, Pandas, Matplotlib, Seaborn)
- Initialized Git repository and `.gitignore`

### Step 2: Data Loading & Initial EDA
- Loaded Kaggle dataset (`insurance_claims.csv`) using PySpark
- Verified schema and data types
- Confirmed **no missing values**
- Explored **target variable (`claim_status`)**
  - 0 â†’ 93.6% (no claim)
  - 1 â†’ 6.4% (claim)
  - â†’ *Highly imbalanced dataset*
- Visualized **distributions of 12 numeric features**
- Documented feature types and potential preprocessing needs

---

## ğŸ“Š Key Insights So Far
- Data quality: No missing values detected.
- Target imbalance: Significant (only ~6% claims).
- Several features require cleaning (e.g., `max_torque`, `max_power`).
- Many â€œYes/Noâ€ columns need binary encoding.
- Possible multicollinearity between size-related variables (`length`, `width`, `gross_weight`).

---

## Next Steps
**Step 3: Data Preprocessing**
- Convert column types (string â†’ numeric)
- Encode binary categorical features (`is_*` columns)
- Parse mixed-format features (`max_torque`, `max_power`)
- Drop irrelevant IDs (`policy_id`)
- Save a clean dataset for feature engineering

---

## Tech Stack
- **Language:** Python 3.12  
- **Core Libraries:** PySpark, Pandas, Matplotlib, Seaborn  
- **Environment:** VS Code  
- **Dataset:** [Kaggle â€“ Insurance Claims Dataset](https://www.kaggle.com/datasets/litvinenko630/insurance-claims)

---

## âœï¸ Author
Project by *Maryna Kyslytsyna* â€” built for portfolio and PySpark practice.

